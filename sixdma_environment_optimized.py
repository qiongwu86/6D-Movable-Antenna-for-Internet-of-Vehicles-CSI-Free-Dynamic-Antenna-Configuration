import time
import numpy as np
from typing import List, Dict, Tuple, Optional
import gymnasium as gym
from gymnasium import spaces
from dataclasses import dataclass
import copy
import threading
from concurrent.futures import ThreadPoolExecutor
import hashlib

from sixDMA_Environment_core_class import SystemParams, ActionSpace, UserMobility, Surface, Antenna, ChannelModel
#from enhanced_reward_system import EnhancedRewardCalculator, TrainingDiagnostics


class OptimizedChannelCache:
    """ä¼˜åŒ–çš„ä¿¡é“ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_cache_size: int = 20000, enable_parallel: bool = True):
        self.cache = {}
        self.cache_stats = {'hits': 0, 'misses': 0, 'computations': 0}
        self.max_cache_size = max_cache_size
        self.enable_parallel = enable_parallel
        self._lock = threading.Lock()
        
        # çº¿ç¨‹æ± ç”¨äºå¹¶è¡Œè®¡ç®—
        if enable_parallel:
            self.executor = ThreadPoolExecutor(max_workers=4)
        else:
            self.executor = None
    
    def _generate_cache_key(self, antenna_pos: np.ndarray, user_pos: np.ndarray, 
                          antenna_normal: np.ndarray, user_type: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # å¯¹ä½ç½®è¿›è¡Œç½‘æ ¼åŒ–ä»¥å¢åŠ ç¼“å­˜å‘½ä¸­ç‡
        grid_resolution = 0.5  # 0.5ç±³ç½‘æ ¼
        
        antenna_grid = tuple(np.round(antenna_pos / grid_resolution) * grid_resolution)
        user_grid = tuple(np.round(user_pos / grid_resolution) * grid_resolution)
        normal_grid = tuple(np.round(antenna_normal, 2))
        
        key_str = f"{antenna_grid}_{user_grid}_{normal_grid}_{user_type}"
        return hashlib.md5(key_str.encode()).hexdigest()[:16]
    
    def get_channel_coefficient(self, antenna: Antenna, user, params: SystemParams) -> complex:
        """è·å–ä¿¡é“ç³»æ•°ï¼Œä½¿ç”¨ç¼“å­˜ä¼˜åŒ–"""
        cache_key = self._generate_cache_key(
            antenna.position, user.position, antenna.normal, user.type
        )
        
        # æ£€æŸ¥ç¼“å­˜
        with self._lock:
            if cache_key in self.cache:
                self.cache_stats['hits'] += 1
                return self.cache[cache_key]
            
            self.cache_stats['misses'] += 1
        
        # è®¡ç®—ä¿¡é“ç³»æ•°
        coefficient = self._compute_channel_coefficient(antenna, user, params)
        
        # ç¼“å­˜ç»“æœ
        with self._lock:
            if len(self.cache) >= self.max_cache_size:
                # ç®€å•çš„FIFOç¼“å­˜æ›¿æ¢ç­–ç•¥
                oldest_key = next(iter(self.cache))
                del self.cache[oldest_key]
            
            self.cache[cache_key] = coefficient
            self.cache_stats['computations'] += 1
        
        return coefficient
    
    def _compute_channel_coefficient(self, antenna: Antenna, user, params: SystemParams) -> complex:
        """è®¡ç®—ä¿¡é“ç³»æ•°"""
        distance = np.linalg.norm(user.position - antenna.position)
        
        # è®¡ç®—å¤©çº¿å¢ç›Š
        antenna_gain_linear = ChannelModel.calculate_3gpp_antenna_gain(
            antenna, user, params)
        
        # æ ¹æ®ç”¨æˆ·ç±»å‹é€‰æ‹©ä¿¡é“æ¨¡å‹
        if user.type == 'vehicle':
            return ChannelModel.vehicle_channel_model_simplified(
                distance, antenna_gain_linear, antenna, user, params)
        else:
            return ChannelModel.uav_channel_model_v2(
                distance, antenna_gain_linear, user, params)
    
    def compute_channel_matrix_batch(self, antennas: List[Antenna], users: List, 
                                   params: SystemParams) -> np.ndarray:
        """æ‰¹é‡è®¡ç®—ä¿¡é“çŸ©é˜µ"""
        num_antennas = len(antennas)
        num_users = len(users)
        H = np.zeros((num_antennas, num_users), dtype=complex)
        
        if self.enable_parallel and self.executor:
            # å¹¶è¡Œè®¡ç®—
            futures = []
            for u, user in enumerate(users):
                for a, antenna in enumerate(antennas):
                    future = self.executor.submit(
                        self.get_channel_coefficient, antenna, user, params
                    )
                    futures.append((a, u, future))
            
            for a, u, future in futures:
                H[a, u] = future.result()
        else:
            # ä¸²è¡Œè®¡ç®—
            for u, user in enumerate(users):
                for a, antenna in enumerate(antennas):
                    H[a, u] = self.get_channel_coefficient(antenna, user, params)
        
        return H
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self._lock:
            self.cache.clear()
            self.cache_stats = {'hits': 0, 'misses': 0, 'computations': 0}
    
    def get_cache_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        with self._lock:
            total = self.cache_stats['hits'] + self.cache_stats['misses']
            hit_rate = self.cache_stats['hits'] / total if total > 0 else 0
            return {
                'cache_size': len(self.cache),
                'hit_rate': hit_rate,
                'total_accesses': total,
                **self.cache_stats
            }


class VectorizedStateManager:
    """å‘é‡åŒ–çŠ¶æ€ç®¡ç†å™¨ - æ™ºèƒ½ä½“ä¸ºä¸­å¿ƒçš„çŠ¶æ€è¡¨ç¤º"""
    
    def __init__(self, params: SystemParams):
        self.params = params
        
        # çŠ¶æ€ç»„ä»¶å¤§å°
        self.grid_size = params.grid_x * params.grid_y * params.grid_z
        self.neighbor_size = 8
        self.surface_state_size = params.num_surfaces * 6  # æ¯ä¸ªè¡¨é¢6ä¸ªç‰¹å¾
        
        # æ€»çŠ¶æ€å¤§å°ä¿æŒä¸å˜ï¼Œä½†å†…éƒ¨é‡æ–°æ’åº
        self.total_state_size = self.grid_size + self.neighbor_size + self.surface_state_size
        
        # é¢„åˆ†é…æ•°ç»„ä»¥é¿å…é‡å¤åˆ†é…
        self.user_density_grid = np.zeros((params.grid_x, params.grid_y, params.grid_z))
        self.state_buffer = np.zeros((params.num_surfaces, self.total_state_size))
        
        print(f"å¯ç”¨æ™ºèƒ½ä½“ä¸ºä¸­å¿ƒçš„çŠ¶æ€è¡¨ç¤ºï¼ŒçŠ¶æ€å¤§å°: {self.total_state_size}")
    
    def compute_all_states_vectorized(self, users: List, surfaces: List[Surface], 
                                    occupied_positions: set, 
                                    current_position_indices: List[int],
                                    action_space_manager: ActionSpace) -> np.ndarray:
        """å‘é‡åŒ–è®¡ç®—æ‰€æœ‰æ™ºèƒ½ä½“çŠ¶æ€"""
        # é‡ç½®ç¼“å†²åŒº
        self.user_density_grid.fill(0)
        self.state_buffer.fill(0)
        
        # 1. è®¡ç®—ç”¨æˆ·å¯†åº¦ç½‘æ ¼ï¼ˆå‘é‡åŒ–ï¼‰
        user_positions = np.array([user.position for user in users])
        if len(user_positions) > 0:
            self._compute_user_density_vectorized(user_positions)
        
        # 2. ä¸ºæ‰€æœ‰æ™ºèƒ½ä½“è®¡ç®—çŠ¶æ€
        for agent_id in range(self.params.num_surfaces):
            state = self._get_agent_state_optimized(
                agent_id, surfaces, occupied_positions, 
                current_position_indices, action_space_manager
            )
            self.state_buffer[agent_id] = state
        
        return self.state_buffer.copy()
    
    def _compute_user_density_vectorized(self, user_positions: np.ndarray):
        """å‘é‡åŒ–è®¡ç®—ç”¨æˆ·å¯†åº¦ç½‘æ ¼"""
        # ç½‘æ ¼å°ºå¯¸
        x_step = self.params.environment_size[0] / self.params.grid_x
        y_step = self.params.environment_size[1] / self.params.grid_y
        z_step = self.params.environment_size[2] / self.params.grid_z
        
        # å‘é‡åŒ–è®¡ç®—ç½‘æ ¼ç´¢å¼•
        grid_indices = np.floor(user_positions / np.array([x_step, y_step, z_step])).astype(int)
        
        # é™åˆ¶ç´¢å¼•èŒƒå›´
        grid_indices[:, 0] = np.clip(grid_indices[:, 0], 0, self.params.grid_x - 1)
        grid_indices[:, 1] = np.clip(grid_indices[:, 1], 0, self.params.grid_y - 1)
        grid_indices[:, 2] = np.clip(grid_indices[:, 2], 0, self.params.grid_z - 1)
        
        # ç´¯åŠ ç”¨æˆ·åˆ°ç½‘æ ¼
        for idx in grid_indices:
            self.user_density_grid[idx[0], idx[1], idx[2]] += 1
        
        # å½’ä¸€åŒ–
        max_users_per_grid = 2
        self.user_density_grid = np.clip(self.user_density_grid / max_users_per_grid, 0, 1)
    
    def _get_agent_state_optimized(self, agent_id: int, surfaces: List[Surface],
                                 occupied_positions: set, current_position_indices: List[int],
                                 action_space_manager: ActionSpace) -> np.ndarray:
        """æ™ºèƒ½ä½“ä¸ºä¸­å¿ƒçš„çŠ¶æ€è®¡ç®— - å½“å‰æ™ºèƒ½ä½“ä¿¡æ¯æ’åœ¨å‰é¢"""
        state_components = []
        
        # 1. ç”¨æˆ·å¯†åº¦ç½‘æ ¼ï¼ˆå…¨å±€ä¿¡æ¯ï¼Œæ‰€æœ‰æ™ºèƒ½ä½“å…±äº«ï¼‰
        state_components.append(self.user_density_grid.flatten())
        
        # 2. é‚»è¿‘ä½ç½®å ç”¨çŠ¶æ€ï¼ˆä¸ªä½“ä¿¡æ¯ï¼‰
        neighbor_occupancy = self._get_neighbor_occupancy_fast(
            agent_id, occupied_positions, current_position_indices, action_space_manager
        )
        state_components.append(neighbor_occupancy)
        
        # 3. æ™ºèƒ½ä½“ä¸ºä¸­å¿ƒé‡æ’åºçš„è¡¨é¢çŠ¶æ€
        agent_centric_surface_state = self._get_agent_centric_surface_state(agent_id, surfaces)
        state_components.append(agent_centric_surface_state)
        
        # æ‹¼æ¥çŠ¶æ€
        full_state = np.concatenate(state_components)
        
        # ç¡®ä¿çŠ¶æ€ç»´åº¦æ­£ç¡®
        if len(full_state) < self.total_state_size:
            padding = np.zeros(self.total_state_size - len(full_state))
            full_state = np.concatenate([full_state, padding])
        elif len(full_state) > self.total_state_size:
            full_state = full_state[:self.total_state_size]
        
        # ç¨€ç–çŠ¶æ€é¢„å¤„ç†ï¼šå¢å¼ºéé›¶ç‰¹å¾
        processed_state = self._preprocess_sparse_state(full_state)
        
        return processed_state.astype(np.float32)
    
    def _preprocess_sparse_state(self, state: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†ç¨€ç–çŠ¶æ€ï¼šå¢å¼ºé‡è¦ç‰¹å¾"""
        # åˆ†ç¦»ä¸åŒç»„ä»¶
        grid_end = self.grid_size
        neighbor_end = grid_end + self.neighbor_size
        
        user_density = state[:grid_end]
        neighbor_info = state[grid_end:neighbor_end]
        surface_info = state[neighbor_end:]
        
        # å¢å¼ºç”¨æˆ·å¯†åº¦ä¿¡æ¯ï¼šå¯¹éé›¶å€¼è¿›è¡Œç¼©æ”¾
        enhanced_density = np.where(user_density > 0, 
                                  np.sqrt(user_density) + 0.1,  # å¢å¼ºéé›¶å€¼
                                  user_density)
        
        # é‚»å±…ä¿¡æ¯æ ‡å‡†åŒ–
        enhanced_neighbor = neighbor_info / (np.linalg.norm(neighbor_info) + 1e-8)
        
        # è¡¨é¢ä¿¡æ¯åˆ†ç»„å¤„ç†
        surface_reshaped = surface_info.reshape(-1, 6)  # æ¯ä¸ªè¡¨é¢6ä¸ªç‰¹å¾
        enhanced_surface = []
        for surface_state in surface_reshaped:
            # ä½ç½®ä¿¡æ¯ï¼ˆå‰3ç»´ï¼‰å’Œè§’åº¦ä¿¡æ¯ï¼ˆå3ç»´ï¼‰åˆ†åˆ«å¤„ç†
            pos_info = surface_state[:3]
            angle_info = surface_state[3:]
            
            # ä½ç½®æ ‡å‡†åŒ–
            pos_norm = pos_info / (np.linalg.norm(pos_info) + 1e-8)
            # è§’åº¦ä¿¡æ¯ä¿æŒåŸå€¼ä½†å¢å¼ºèŒƒå›´
            angle_enhanced = np.tanh(angle_info * 2.0)
            
            enhanced_surface.extend(pos_norm)
            enhanced_surface.extend(angle_enhanced)
        
        enhanced_surface = np.array(enhanced_surface)
        
        # é‡æ–°ç»„åˆ
        processed_state = np.concatenate([
            enhanced_density,
            enhanced_neighbor, 
            enhanced_surface
        ])
        
        return processed_state
    
    def _get_agent_centric_surface_state(self, agent_id: int, surfaces: List[Surface]) -> np.ndarray:
        """è·å–æ™ºèƒ½ä½“ä¸ºä¸­å¿ƒé‡æ’åºçš„è¡¨é¢çŠ¶æ€ï¼šå½“å‰æ™ºèƒ½ä½“çš„è¡¨é¢æ”¾åœ¨ç¬¬ä¸€ä½"""
        surface_states = []
        
        # é¦–å…ˆæ·»åŠ å½“å‰æ™ºèƒ½ä½“çš„è¡¨é¢çŠ¶æ€ï¼ˆæ ‡è®°ä¸ºè‡ªå·±ï¼‰
        if agent_id < len(surfaces):
            current_surface = surfaces[agent_id]
            pos_normalized = current_surface.center / np.array(self.params.environment_size)
            azimuth_norm = (current_surface.azimuth + 180) / 360
            elevation_norm = (current_surface.elevation + 90) / 180
            
            # æœ€åä¸€ä¸ªç‰¹å¾è®¾ä¸º1.0ï¼Œæ ‡è®°è¿™æ˜¯å½“å‰æ™ºèƒ½ä½“
            current_state = np.array([
                pos_normalized[0], pos_normalized[1], pos_normalized[2],
                azimuth_norm, elevation_norm, 1.0
            ])
            surface_states.append(current_state)
        
        # ç„¶åæŒ‰é¡ºåºæ·»åŠ å…¶ä»–æ™ºèƒ½ä½“çš„è¡¨é¢çŠ¶æ€ï¼ˆæ ‡è®°ä¸ºå…¶ä»–æ™ºèƒ½ä½“ï¼‰
        for i, surface in enumerate(surfaces):
            if i != agent_id:
                pos_normalized = surface.center / np.array(self.params.environment_size)
                azimuth_norm = (surface.azimuth + 180) / 360
                elevation_norm = (surface.elevation + 90) / 180
                
                # æœ€åä¸€ä¸ªç‰¹å¾è®¾ä¸º0.0ï¼Œæ ‡è®°è¿™æ˜¯å…¶ä»–æ™ºèƒ½ä½“
                other_state = np.array([
                    pos_normalized[0], pos_normalized[1], pos_normalized[2],
                    azimuth_norm, elevation_norm, 0.0
                ])
                surface_states.append(other_state)
        
        # å¡«å……åˆ°å›ºå®šé•¿åº¦ï¼ˆå¦‚æœè¡¨é¢ä¸è¶³ï¼‰
        while len(surface_states) < self.params.num_surfaces:
            surface_states.append(np.zeros(6))
        
        return np.concatenate(surface_states)
    
    def _get_neighbor_occupancy_fast(self, agent_id: int, occupied_positions: set,
                                   current_position_indices: List[int],
                                   action_space_manager: ActionSpace) -> np.ndarray:
        """å¿«é€Ÿè®¡ç®—é‚»å±…å ç”¨çŠ¶æ€"""
        if agent_id >= len(current_position_indices):
            return np.zeros(self.neighbor_size)
        
        current_pos_idx = current_position_indices[agent_id]
        neighbors = action_space_manager.neighbors.get(current_pos_idx, {})
        direction_names = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']
        
        occupancy = np.zeros(8)
        for i, direction in enumerate(direction_names):
            neighbor_pos_idx = neighbors.get(direction, None)
            if neighbor_pos_idx is not None and neighbor_pos_idx in occupied_positions:
                occupancy[i] = 1.0
        
        return occupancy
    
    def _get_all_surface_state_vectorized(self, surfaces: List[Surface]) -> np.ndarray:
        """å‘é‡åŒ–è®¡ç®—æ‰€æœ‰è¡¨é¢çŠ¶æ€"""
        surface_states = []
        
        for surface in surfaces:
            # ä½ç½®å½’ä¸€åŒ–åˆ°[0,1]
            pos_normalized = surface.center / np.array(self.params.environment_size)
            
            # è§’åº¦å½’ä¸€åŒ–
            azimuth_norm = (surface.azimuth + 180) / 360
            elevation_norm = (surface.elevation + 90) / 180
            
            surface_state = np.array([
                pos_normalized[0], pos_normalized[1], pos_normalized[2],
                azimuth_norm, elevation_norm, 1.0
            ])
            surface_states.append(surface_state)
        
        # å¦‚æœè¡¨é¢ä¸è¶³ï¼Œå¡«å……é›¶
        while len(surface_states) < self.params.num_surfaces:
            surface_states.append(np.zeros(6))
        
        return np.concatenate(surface_states)


class OptimizedSixDMAEnvironment(gym.Env):
    """ä¼˜åŒ–çš„6DMAå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ"""
    
    def __init__(self, params: SystemParams, enable_cache: bool = True, enable_parallel: bool = True):
        super().__init__()
        self.params = params
        self.action_space_manager = ActionSpace(params)
        self.max_episode_steps = 50
        
        # ä¼˜åŒ–ç»„ä»¶
        self.channel_cache = OptimizedChannelCache(enable_parallel=enable_parallel) if enable_cache else None
        self.state_manager = VectorizedStateManager(params)
        
        # åˆå§‹åŒ–ç”¨æˆ·å’Œè¡¨é¢
        self.users = UserMobility.generate_user_positions(params)
        self.surfaces = []
        self.antennas = []
        
        # Episodeçº§åˆ«çš„ä¿¡é“çŸ©é˜µç¼“å­˜
        self.episode_channel_matrix = None
        self.episode_channel_valid = False
        self.users_positions_cache = None
        
        # Episodeç»Ÿè®¡
        self.episode_count = 0
        self.episode_rewards_history = []
        self.episode_capacities_history = []
        self.episode_losses_history = []
        self.full_reset_count = 0  # å®Œå…¨é‡ç½®æ¬¡æ•°ç»Ÿè®¡
        
        # å¢å¼ºå¥–åŠ±ç³»ç»Ÿ
        # self.enhanced_reward_calculator = EnhancedRewardCalculator(params)
        # self.training_diagnostics = TrainingDiagnostics()
        
        # çŠ¶æ€å’ŒåŠ¨ä½œç©ºé—´
        self.state_size = self.state_manager.total_state_size
        self.local_action_size = 9 * 9
        
        # Gym spaces
        self.observation_space = spaces.Box(
            low=0.0, high=1.0, shape=(self.state_size,), dtype=np.float32
        )
        self.action_space = spaces.Box(
            low=0.0, high=1.0, shape=(self.local_action_size,), dtype=np.float32
        )
        
        # å½“å‰çŠ¶æ€
        self.current_surface_position_indices = []
        self.occupied_position_indices = set()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'step_times': [],
            'channel_compute_times': [],
            'state_compute_times': [],
            'action_execute_times': []
        }
        
        print(f"ä¼˜åŒ–6DMAç¯å¢ƒåˆå§‹åŒ–å®Œæˆ:")
        print(f"  ç¼“å­˜å¯ç”¨: {enable_cache}")
        print(f"  å¹¶è¡Œè®¡ç®—: {enable_parallel}")
        print(f"  Episodeçº§ä¿¡é“ç¼“å­˜: å¯ç”¨")
        print(f"  çŠ¶æ€ç©ºé—´å¤§å°: {self.state_size}")
        print(f"  å±€éƒ¨åŠ¨ä½œç©ºé—´å¤§å°: {self.local_action_size}")
    
    def reset(self, seed: Optional[int] = None) -> Tuple[np.ndarray, Dict]:
        """é‡ç½®ç¯å¢ƒ - Episodeé—´æ›´æ–°ç”¨æˆ·ä½ç½®ï¼Œæ¯100ä¸ªepisodeå®Œå…¨é‡ç½®"""
        # å–æ¶ˆå›ºå®šéšæœºç§å­ï¼Œä½¿ç”¨æ›´çœŸå®çš„éšæœºæ€§
        if seed is not None:
            np.random.seed(seed)
        
        # Episodeè®¡æ•°
        self.episode_count += 1
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å®Œå…¨é‡ç½®ï¼ˆæ¯100ä¸ªepisodeï¼‰
        is_full_reset = (self.episode_count % 100 == 1) or (self.episode_count == 1)
        
        if is_full_reset:
            # å®Œå…¨é‡ç½®ï¼šé‡æ–°ç”Ÿæˆç”¨æˆ·ä½ç½®å’Œå¤©çº¿ä½ç½®
            self.full_reset_count += 1
            print(f"Episode {self.episode_count}: å®Œå…¨é‡ç½®ç¯å¢ƒ (ç¬¬{self.full_reset_count}æ¬¡å®Œå…¨é‡ç½®)")
            # ä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºéšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡é‡ç½®éƒ½äº§ç”Ÿä¸åŒçš„ç”¨æˆ·åˆ†å¸ƒ
            random_seed = int(time.time() * 1000) % 10000
            self.users = UserMobility.generate_user_positions(self.params, seed=random_seed)
            self._initialize_surfaces_optimized()
            print(f"  - é‡æ–°ç”Ÿæˆç”¨æˆ·åˆ†å¸ƒ (éšæœºç§å­: {random_seed})")
            print(f"  - é‡æ–°åˆå§‹åŒ–å¤©çº¿ä½ç½®")
        else:
            # æ¸è¿›å¼æ›´æ–°ï¼šä¿æŒå¤©çº¿ä½ç½®ï¼Œæ›´æ–°ç”¨æˆ·ä½ç½®
            self._update_users_between_episodes()
            print(f"Episode {self.episode_count}: æ¸è¿›å¼æ›´æ–°ç”¨æˆ·ä½ç½®ï¼Œä¿æŒå¤©çº¿ä½ç½®")
        
        # è®¡ç®—çœŸå®çš„episodeåˆå§‹å®¹é‡ï¼ˆåŸºäºå½“å‰è½¦è¾†ä½ç½®å’Œå¤©çº¿ä½ç½®ï¼‰
        true_initial_capacity = self._calculate_system_capacity_optimized()
        print(f"Episode {self.episode_count}: çœŸå®åˆå§‹å®¹é‡ = {true_initial_capacity:.1f}")
        
        # é‡ç½®å¢å¼ºå¥–åŠ±ç³»ç»Ÿçš„episodeç»Ÿè®¡
        if hasattr(self, 'enhanced_reward_calculator'):
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¬¡é‡ç½®ï¼Œå…ˆå®Œæˆä¸Šä¸€ä¸ªepisodeï¼ˆæ›´æ–°åŠ¨æ€åŸºå‡†ï¼‰
            if self.episode_count > 0:
                self.enhanced_reward_calculator.complete_episode()
            
            # é‡ç½®å½“å‰episode
            self.enhanced_reward_calculator.reset_episode()
        
        # é¢„è®¡ç®—Episodeçº§åˆ«çš„ä¿¡é“çŸ©é˜µ
        self._precompute_episode_channel_matrix()
        
        # é‡ç½®episodeç»Ÿè®¡
        self.episode_step = 0
        self.current_episode_rewards = []
        self.current_episode_capacities = []
        
        # è®¡ç®—åˆå§‹çŠ¶æ€
        start_time = time.time()
        states = self.state_manager.compute_all_states_vectorized(
            self.users, self.surfaces, self.occupied_position_indices,
            self.current_surface_position_indices, self.action_space_manager
        )
        state_time = time.time() - start_time
        
        # è®¡ç®—åˆå§‹å®¹é‡ï¼ˆä½¿ç”¨ç¼“å­˜çš„ä¿¡é“çŸ©é˜µï¼‰
        start_time = time.time()
        total_capacity = self._calculate_system_capacity_with_cached_matrix()
        capacity_time = time.time() - start_time
        
        info = self._get_info_optimized(total_capacity, state_time, capacity_time)
        info['episode_count'] = self.episode_count
        info['channel_matrix_cached'] = self.episode_channel_valid
        
        return states, info
    
    def step(self, actions: List[np.ndarray]) -> Tuple[np.ndarray, List[float], List[bool], List[bool], Dict]:
        """ä¼˜åŒ–çš„ç¯å¢ƒæ­¥è¿› - Episodeå†…ç”¨æˆ·ä½ç½®å›ºå®š"""
        step_start_time = time.time()
        self.episode_step += 1
        
        # 1. æ‰§è¡ŒåŠ¨ä½œï¼ˆç”¨æˆ·ä½ç½®åœ¨episodeå†…ä¿æŒä¸å˜ï¼‰
        action_start = time.time()
        valid_actions = self._execute_actions_optimized(actions)
        action_time = time.time() - action_start
        
        # 2. è®¡ç®—å¥–åŠ±ï¼ˆä½¿ç”¨ç¼“å­˜çš„ä¿¡é“çŸ©é˜µï¼‰
        reward_start = time.time()
        rewards, total_rate = self._calculate_rewards_optimized(valid_actions)
        reward_time = time.time() - reward_start
        
        # 3. æ”¶é›†episodeç»Ÿè®¡
        self.current_episode_rewards.extend(rewards)
        self.current_episode_capacities.append(total_rate)
        
        # 4. æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        terminated = [False] * self.params.num_surfaces
        truncated = [self.episode_step >= self.max_episode_steps] * self.params.num_surfaces
        
        # 5. è·å–æ–°çŠ¶æ€
        state_start = time.time()
        next_states = self.state_manager.compute_all_states_vectorized(
            self.users, self.surfaces, self.occupied_position_indices,
            self.current_surface_position_indices, self.action_space_manager
        )
        state_time = time.time() - state_start
        
        # 6. Episodeç»“æŸæ—¶çš„ç»Ÿè®¡è¾“å‡º
        if any(terminated) or any(truncated):
            self._log_episode_summary()
        
        # 7. ç”Ÿæˆä¿¡æ¯
        total_step_time = time.time() - step_start_time
        info = self._get_info_optimized(total_rate, state_time, reward_time)
        info['users_positions_fixed'] = True
        info['channel_matrix_cached'] = self.episode_channel_valid
        
        # 8. æ›´æ–°æ€§èƒ½ç»Ÿè®¡
        self.performance_stats['step_times'].append(total_step_time)
        self.performance_stats['channel_compute_times'].append(reward_time)
        self.performance_stats['state_compute_times'].append(state_time)
        self.performance_stats['action_execute_times'].append(action_time)
        
        return next_states, rewards, terminated, truncated, info
    
    def _initialize_surfaces_optimized(self):
        """ä¼˜åŒ–çš„è¡¨é¢åˆå§‹åŒ–"""
        self.surfaces = []
        self.antennas = []
        self.occupied_position_indices = set()
        
        # æ‰¹é‡é€‰æ‹©ä½ç½®
        available_positions = list(range(len(self.action_space_manager.all_positions)))
        selected_positions = np.random.choice(
            available_positions, size=self.params.num_surfaces, replace=False
        )
        
        self.current_surface_position_indices = selected_positions.tolist()
        
        # æ‰¹é‡åˆ›å»ºè¡¨é¢å’Œå¤©çº¿
        center = np.array(self.params.base_station_pos)
        
        for s, pos_idx in enumerate(selected_positions):
            position = self.action_space_manager.all_positions[pos_idx]
            radial_normal = (position - center) / np.linalg.norm(position - center)
            
            surface = Surface(
                id=s, center=position.copy(), normal=radial_normal.copy(),
                azimuth=np.degrees(np.arctan2(radial_normal[1], radial_normal[0])),
                elevation=np.degrees(np.arcsin(radial_normal[2]))
            )
            self.surfaces.append(surface)
            self.occupied_position_indices.add(pos_idx)
            
            # ç”Ÿæˆå¤©çº¿é˜µåˆ—
            antenna_positions = self._generate_surface_antenna_array_vectorized(surface)
            
            for a in range(self.params.antennas_per_surface):
                antenna = Antenna(
                    surface_id=s,
                    global_id=s * self.params.antennas_per_surface + a,
                    local_id=a,
                    position=antenna_positions[a].copy(),
                    normal=surface.normal.copy(),
                    surface_center=surface.center.copy()
                )
                self.antennas.append(antenna)
                surface.antennas.append(antenna)
    
    def _generate_surface_antenna_array_vectorized(self, surface: Surface) -> np.ndarray:
        """å‘é‡åŒ–ç”Ÿæˆè¡¨é¢å¤©çº¿é˜µåˆ—"""
        center = surface.center
        normal = surface.normal
        spacing = self.params.antenna_spacing
        
        # æ„å»ºå±€éƒ¨åæ ‡ç³»
        if abs(normal[2]) < 0.9:
            ref_vec = np.array([0, 0, 1])
        else:
            ref_vec = np.array([1, 0, 0])
        
        u = np.cross(normal, ref_vec)
        u = u / np.linalg.norm(u)
        v = np.cross(normal, u)
        
        # 2x2é˜µåˆ—æœ¬åœ°ä½ç½®ï¼ˆå‘é‡åŒ–ï¼‰
        local_positions = np.array([
            [-spacing/2, -spacing/2, 0],
            [spacing/2, -spacing/2, 0],
            [-spacing/2, spacing/2, 0],
            [spacing/2, spacing/2, 0]
        ])
        
        # å‘é‡åŒ–è½¬æ¢åˆ°å…¨å±€åæ ‡
        local_offsets = local_positions[:, 0:1] * u + local_positions[:, 1:2] * v
        antenna_positions = center + local_offsets
        
        return antenna_positions
    
    def _execute_actions_optimized(self, actions: List[np.ndarray]) -> List[bool]:
        """ä¼˜åŒ–çš„åŠ¨ä½œæ‰§è¡Œ"""
        valid_actions = []
        new_position_indices = set()
        
        # æ‰¹é‡å¤„ç†åŠ¨ä½œ
        for agent_id, action_probs in enumerate(actions):
            if agent_id >= len(self.current_surface_position_indices):
                valid_actions.append(False)
                continue
            
            current_pos_idx = self.current_surface_position_indices[agent_id]
            local_action_indices, action_matrix = self.action_space_manager.get_local_action_space(current_pos_idx)
            
            if len(local_action_indices) == 0 or action_matrix.size == 0:
                valid_actions.append(False)
                continue
            
            # å¿«é€ŸåŠ¨ä½œé€‰æ‹©
            success, target_pos_idx, selected_action = self._select_best_action_fast(
                action_probs, action_matrix, current_pos_idx
            )
            
            if success:
                self._move_surface_to_position_fast(agent_id, target_pos_idx, selected_action)
                valid_actions.append(True)
                new_position_indices.add(target_pos_idx)
            else:
                valid_actions.append(False)
                new_position_indices.add(current_pos_idx)
        
        # æ›´æ–°å ç”¨ä½ç½®
        self.occupied_position_indices = new_position_indices
        return valid_actions
    
    def _select_best_action_fast(self, action_probs: np.ndarray, action_matrix: np.ndarray, 
                               current_pos_idx: int) -> Tuple[bool, int, Dict]:
        """å¿«é€ŸåŠ¨ä½œé€‰æ‹©"""
        # ç¡®ä¿åŠ¨ä½œæ¦‚ç‡ç»´åº¦æ­£ç¡®
        if len(action_probs) != self.local_action_size:
            action_probs = np.resize(action_probs, self.local_action_size)
        
        # é‡å¡‘ä¸º9Ã—9çŸ©é˜µ
        action_matrix_probs = action_probs.reshape(9, 9)
        
        # æ‰¾åˆ°æœ€ä¼˜å¯ç”¨åŠ¨ä½œ
        best_prob = -1
        best_position = None
        best_rotation = None
        
        for pos_i in range(min(9, action_matrix.shape[0])):
            if action_matrix[pos_i, 0] != -1:
                target_pos_idx = self.action_space_manager.position_rotation_pairs[
                    action_matrix[pos_i, 0]]['position_idx']
                
                if (target_pos_idx not in self.occupied_position_indices or 
                    target_pos_idx == current_pos_idx):
                    
                    # ä½¿ç”¨softmaxé€‰æ‹©æ—‹è½¬
                    pos_probs = action_matrix_probs[pos_i, :]
                    softmax_probs = np.exp(pos_probs - np.max(pos_probs))
                    softmax_probs /= np.sum(softmax_probs)
                    
                    selected_rot = np.random.choice(9, p=softmax_probs)
                    prob = softmax_probs[selected_rot]
                    
                    if prob > best_prob:
                        best_prob = prob
                        best_position = pos_i
                        best_rotation = selected_rot
        
        if best_position is not None and best_rotation < action_matrix.shape[1]:
            selected_action_idx = action_matrix[best_position, best_rotation]
            if selected_action_idx != -1:
                selected_action = self.action_space_manager.position_rotation_pairs[selected_action_idx]
                return True, selected_action['position_idx'], selected_action
        
        return False, current_pos_idx, {}
    
    def _move_surface_to_position_fast(self, surface_id: int, target_pos_idx: int, action: Dict):
        """å¿«é€Ÿç§»åŠ¨è¡¨é¢åˆ°ç›®æ ‡ä½ç½®"""
        if surface_id >= len(self.surfaces):
            return
        
        surface = self.surfaces[surface_id]
        
        # æ›´æ–°è¡¨é¢
        surface.center = action['position'].copy()
        surface.normal = action['normal'].copy()
        surface.azimuth = np.degrees(np.arctan2(surface.normal[1], surface.normal[0]))
        surface.elevation = np.degrees(np.arcsin(np.clip(surface.normal[2], -1, 1)))
        
        # æ‰¹é‡æ›´æ–°å¤©çº¿
        new_antenna_positions = self._generate_surface_antenna_array_vectorized(surface)
        for i, antenna in enumerate(surface.antennas):
            antenna.position = new_antenna_positions[i].copy()
            antenna.normal = surface.normal.copy()
            antenna.surface_center = surface.center.copy()
        
        # æ›´æ–°ä½ç½®ç´¢å¼•
        self.current_surface_position_indices[surface_id] = target_pos_idx
    
    def _calculate_rewards_optimized(self, valid_actions: List[bool]) -> Tuple[List[float], float]:
        """ä¼˜åŒ–çš„å¥–åŠ±è®¡ç®— - ä½¿ç”¨å¢å¼ºå¥–åŠ±ç³»ç»Ÿ"""
        # ä½¿ç”¨ç¼“å­˜è®¡ç®—ç³»ç»Ÿå®¹é‡
        total_rate = self._calculate_system_capacity_optimized()
        
        # ä½¿ç”¨å¢å¼ºå¥–åŠ±ç³»ç»Ÿè®¡ç®—ä¸ªä½“åŒ–å¥–åŠ±
        enhanced_rewards, reward_stats = self.enhanced_reward_calculator.calculate_enhanced_rewards(
            current_capacity=total_rate,
            antennas=self.antennas,
            users=self.users,
            valid_actions=valid_actions,
            current_positions=self.current_surface_position_indices,
            occupied_positions=self.occupied_position_indices,
            episode_step=self.episode_step
        )
        
        # å­˜å‚¨å¥–åŠ±ç»Ÿè®¡ä¿¡æ¯
        if hasattr(self, 'current_reward_stats'):
            self.current_reward_stats = reward_stats
        else:
            self.current_reward_stats = reward_stats
        
        return enhanced_rewards, total_rate
    
    def _calculate_system_capacity_optimized(self) -> float:
        """ä¼˜åŒ–çš„ç³»ç»Ÿå®¹é‡è®¡ç®—"""
        if self.channel_cache:
            # ä½¿ç”¨ç¼“å­˜çš„æ‰¹é‡ä¿¡é“çŸ©é˜µè®¡ç®—
            H = self.channel_cache.compute_channel_matrix_batch(
                self.antennas, self.users, self.params
            )
        else:
            # ä¼ ç»Ÿè®¡ç®—æ–¹æ³•
            H = self._calculate_channel_matrix_traditional()
        
        # å‘é‡åŒ–é€Ÿç‡è®¡ç®—
        rates = self._calculate_theoretical_rates_vectorized(H)
        return np.sum(rates)
    
    def _calculate_channel_matrix_traditional(self) -> np.ndarray:
        """ä¼ ç»Ÿä¿¡é“çŸ©é˜µè®¡ç®—ï¼ˆæ— ç¼“å­˜ï¼‰"""
        num_antennas = len(self.antennas)
        num_users = len(self.users)
        H = np.zeros((num_antennas, num_users), dtype=complex)
        
        for u, user in enumerate(self.users):
            for a, antenna in enumerate(self.antennas):
                distance = np.linalg.norm(user.position - antenna.position)
                antenna_gain_linear = ChannelModel.calculate_3gpp_antenna_gain(
                    antenna, user, self.params)
                
                if user.type == 'vehicle':
                    H[a, u] = ChannelModel.vehicle_channel_model_simplified(
                        distance, antenna_gain_linear, antenna, user, self.params)
                else:
                    H[a, u] = ChannelModel.uav_channel_model_v2(
                        distance, antenna_gain_linear, user, self.params)
        
        return H
    
    def _calculate_theoretical_rates_vectorized(self, H: np.ndarray, transmit_power_dBm: float = 23.0) -> np.ndarray:
        """å‘é‡åŒ–è®¡ç®—ç†è®ºé€Ÿç‡
        
        Args:
            H: ä¿¡é“çŸ©é˜µ [num_antennas, num_users]
            transmit_power_dBm: å‘å°„åŠŸç‡ (dBm)ï¼Œé»˜è®¤23dBm (3GPPæ ‡å‡†)
        """
        # ç³»ç»Ÿå‚æ•°
        noise_power_dBm = -174
        bandwidth_MHz = 20
        noise_figure_dB = 7
        
        # å™ªå£°åŠŸç‡
        total_noise_dBm = noise_power_dBm + 10 * np.log10(bandwidth_MHz * 1e6) + noise_figure_dB
        noise_power_W = 10 ** ((total_noise_dBm - 30) / 10)
        
        # å‘å°„åŠŸç‡
        transmit_power_W = 10 ** ((transmit_power_dBm - 30) / 10)
        
        num_users = H.shape[1]
        
        # å‘é‡åŒ–è®¡ç®—ä¿¡å·åŠŸç‡
        signal_powers = transmit_power_W * np.abs(np.einsum('au,au->u', H.conj(), H))
        
        # å‘é‡åŒ–è®¡ç®—å¹²æ‰°åŠŸç‡
        H_conj_H = np.abs(H.conj().T @ H) ** 2  # [num_users, num_users]
        H_norm_squared = np.abs(np.einsum('au,au->u', H.conj(), H))  # [num_users]
        
        interference_powers = np.zeros(num_users)
        for k in range(num_users):
            interference_mask = np.arange(num_users) != k
            interference_powers[k] = transmit_power_W * np.sum(
                H_conj_H[k, interference_mask] / (H_norm_squared[interference_mask] + 1e-10)
            )
        
        # SINRè®¡ç®—
        sinr = signal_powers / (interference_powers + noise_power_W)
        sinr = np.clip(sinr, 1e-6, 1e6)
        
        # é¦™å†œå®¹é‡
        rates = np.log2(1 + sinr) * bandwidth_MHz
        
        return rates
    
    def _get_info_optimized(self, total_capacity: float, state_time: float, capacity_time: float) -> Dict:
        """è·å–ä¼˜åŒ–çš„ç¯å¢ƒä¿¡æ¯"""
        info = {
            'total_capacity': total_capacity,
            'episode_step': self.episode_step,
            'num_users': len(self.users),
            'occupied_positions': len(self.occupied_position_indices),
            'state_compute_time': state_time,
            'capacity_compute_time': capacity_time
        }
        
        # æ·»åŠ ç¼“å­˜ç»Ÿè®¡
        if self.channel_cache:
            cache_stats = self.channel_cache.get_cache_stats()
            info.update({f'cache_{k}': v for k, v in cache_stats.items()})
        
        return info
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        stats = {}
        for key, times in self.performance_stats.items():
            if times:
                stats[key] = {
                    'mean': np.mean(times),
                    'std': np.std(times),
                    'min': np.min(times),
                    'max': np.max(times),
                    'total': np.sum(times)
                }
        
        return stats
    
    def clear_performance_stats(self):
        """æ¸…ç†æ€§èƒ½ç»Ÿè®¡"""
        for key in self.performance_stats:
            self.performance_stats[key].clear()
    
    def _update_users_between_episodes(self):
        """Episodeé—´æ›´æ–°ç”¨æˆ·ä½ç½® - æ¸è¿›å¼ç§»åŠ¨"""
        for user in self.users:
            if user.type == 'vehicle':
                # è½¦è¾†ï¼šæ²¿é“è·¯éšæœºç§»åŠ¨ä¸€æ®µè·ç¦»
                move_distance = np.random.uniform(10, 30)  # 10-30ç±³çš„ç§»åŠ¨
                displacement = user.direction * move_distance
                new_position = user.position + displacement
                
                # è¾¹ç•Œå¤„ç† - ä¿æŒåœ¨é“è·¯èŒƒå›´å†…
                if user.lane in ['north_bound', 'south_bound']:
                    if new_position[1] > 300:
                        new_position[1] = new_position[1] - 300
                    elif new_position[1] < 0:
                        new_position[1] = new_position[1] + 300
                else:
                    if new_position[0] > 300:
                        new_position[0] = new_position[0] - 300
                    elif new_position[0] < 0:
                        new_position[0] = new_position[0] + 300
                
                user.position = new_position
                
            elif user.type == 'UAV':
                # UAVï¼šéšæœºè§’åº¦å’ŒåŠå¾„è°ƒæ•´
                center = np.array([150, 150, user.height])
                current_radius = np.linalg.norm(user.position[:2] - center[:2])
                
                # éšæœºè°ƒæ•´åŠå¾„å’Œè§’åº¦
                radius_change = np.random.uniform(-10, 10)
                new_radius = np.clip(current_radius + radius_change, 20, 80)
                
                angle_change = np.random.uniform(-np.pi/6, np.pi/6)  # Â±30åº¦
                current_angle = np.arctan2(user.position[1] - center[1], user.position[0] - center[0])
                new_angle = current_angle + angle_change
                
                # é«˜åº¦å¾®è°ƒ
                height_change = np.random.uniform(-5, 5)
                new_height = np.clip(user.height + height_change, 
                                   self.params.air_height_range[0], 
                                   self.params.air_height_range[1])
                
                # æ›´æ–°ä½ç½®
                user.position = np.array([
                    center[0] + new_radius * np.cos(new_angle),
                    center[1] + new_radius * np.sin(new_angle),
                    new_height
                ])
                user.height = new_height
                
                # æ›´æ–°ç§»åŠ¨æ–¹å‘
                user.direction = np.array([-np.sin(new_angle), np.cos(new_angle), 0])
        
        # æ ‡è®°ä¿¡é“çŸ©é˜µéœ€è¦æ›´æ–°
        self.episode_channel_valid = False
        print(f"  å·²æ›´æ–° {len(self.users)} ä¸ªç”¨æˆ·ä½ç½®")
    
    def _precompute_episode_channel_matrix(self):
        """é¢„è®¡ç®—å½“å‰episodeçš„ä¿¡é“çŸ©é˜µ"""
        if not self.antennas or not self.users:
            self.episode_channel_valid = False
            return
        
        print(f"  æ­£åœ¨é¢„è®¡ç®—Episode {self.episode_count}çš„ä¿¡é“çŸ©é˜µ...")
        start_time = time.time()
        
        if self.channel_cache:
            # ä½¿ç”¨ä¼˜åŒ–çš„ç¼“å­˜è®¡ç®—
            self.episode_channel_matrix = self.channel_cache.compute_channel_matrix_batch(
                self.antennas, self.users, self.params
            )
        else:
            # ä¼ ç»Ÿè®¡ç®—æ–¹æ³•
            self.episode_channel_matrix = self._calculate_channel_matrix_traditional()
        
        computation_time = time.time() - start_time
        self.episode_channel_valid = True
        
        print(f"  ä¿¡é“çŸ©é˜µé¢„è®¡ç®—å®Œæˆ: {computation_time:.4f}ç§’, å½¢çŠ¶: {self.episode_channel_matrix.shape}")
        
        # ç¼“å­˜ç”¨æˆ·ä½ç½®ä»¥æ£€æµ‹å˜åŒ–
        self.users_positions_cache = np.array([user.position.copy() for user in self.users])
    
    def _calculate_system_capacity_with_cached_matrix(self) -> float:
        """ä½¿ç”¨ç¼“å­˜çš„ä¿¡é“çŸ©é˜µè®¡ç®—ç³»ç»Ÿå®¹é‡"""
        if not self.episode_channel_valid or self.episode_channel_matrix is None:
            # å›é€€åˆ°å®æ—¶è®¡ç®—
            return self._calculate_system_capacity_optimized()
        
        # ä½¿ç”¨ç¼“å­˜çš„ä¿¡é“çŸ©é˜µè®¡ç®—é€Ÿç‡
        rates = self._calculate_theoretical_rates_vectorized(self.episode_channel_matrix)
        return np.sum(rates)
    
    def _log_episode_summary(self):
        """è®°å½•å¹¶è¾“å‡ºEpisodeæ€»ç»“"""
        if not self.current_episode_rewards or not self.current_episode_capacities:
            return
        
        # è®¡ç®—episodeç»Ÿè®¡
        episode_total_reward = sum(self.current_episode_rewards)
        episode_avg_reward = np.mean(self.current_episode_rewards)
        episode_max_capacity = max(self.current_episode_capacities)
        episode_avg_capacity = np.mean(self.current_episode_capacities)
        episode_final_capacity = self.current_episode_capacities[-1]
        
        # å­˜å‚¨å†å²è®°å½•
        self.episode_rewards_history.append(episode_total_reward)
        self.episode_capacities_history.append(episode_avg_capacity)
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡ï¼ˆæœ€è¿‘10ä¸ªepisodeï¼‰
        recent_rewards = self.episode_rewards_history[-10:]
        recent_capacities = self.episode_capacities_history[-10:]
        
        # è¾“å‡ºç²¾ç®€çš„episodeæ€»ç»“
        print(f"\n{'='*60}")
        print(f"Episode {self.episode_count} æ€»ç»“ ({self.episode_step}/{self.max_episode_steps}æ­¥)")
        print(f"{'='*60}")
        
        # åŸºç¡€ç»Ÿè®¡ - å¥–åŠ±ä¸å®¹é‡åˆå¹¶
        print(f"Episodeç»Ÿè®¡:")
        print(f"  æ€»å¥–åŠ±: {episode_total_reward:.4f} | å¹³å‡å¥–åŠ±: {episode_avg_reward:.4f}")
        print(f"  æœ€è¿‘10è½®å¹³å‡å¥–åŠ±: {np.mean(recent_rewards):.4f}")
        
        # å®¹é‡åˆ†æ - åŸºäºåŠ¨æ€åŸºå‡†çš„æ–°æŒ‡æ ‡
        if hasattr(self, 'current_reward_stats') and self.current_reward_stats:
            current_cap = self.current_reward_stats.get('current_capacity', 0)
            avg_cap = self.current_reward_stats.get('episode_avg_capacity', 0)
            max_cap = self.current_reward_stats.get('episode_max_capacity', 0)
            dynamic_baseline = self.current_reward_stats.get('dynamic_baseline', 0)
            baseline_episodes_count = self.current_reward_stats.get('baseline_episodes_count', 0)
            
            print(f"å®¹é‡åˆ†æ:")
            print(f"  å½“å‰: {current_cap:.1f} | å¹³å‡: {avg_cap:.1f} | æœ€å¤§: {max_cap:.1f} Mbps")
            print(f"  æœ€è¿‘10è½®å¹³å‡: {np.mean(recent_capacities):.2f} Mbps")
            print(f"  åŠ¨æ€åŸºå‡†: {dynamic_baseline:.1f} Mbps (åŸºäº{baseline_episodes_count}ä¸ªepisode)")
            
            # åŠ¨æ€åŸºå‡†æ”¹è¿›æŒ‡æ ‡
            step_improvement = self.current_reward_stats.get('step_improvement', 0)
            baseline_improvement = self.current_reward_stats.get('dynamic_baseline_improvement', 0)
            print(f"  æ”¹è¿›æŒ‡æ ‡: æ­¥è¿› {step_improvement:+.1f}% | ç›¸å¯¹åŠ¨æ€åŸºå‡† {baseline_improvement:+.1f}%")
        else:
            print(f"å®¹é‡åˆ†æ:")
            print(f"  å½“å‰: {episode_final_capacity:.1f} | å¹³å‡: {episode_avg_capacity:.1f} | æœ€å¤§: {episode_max_capacity:.1f} Mbps")
            print(f"  æœ€è¿‘10è½®å¹³å‡: {np.mean(recent_capacities):.2f} Mbps")
        
        # å¥–åŠ±ç»„ä»¶åˆ†æ - åŸºäºåŠ¨æ€åŸºå‡†çš„æ–°ç»„ä»¶
        if hasattr(self, 'current_reward_stats') and self.current_reward_stats:
            print(f"å¥–åŠ±ç»„ä»¶ (åŠ¨æ€åŸºå‡†ç‰ˆæœ¬):")
            abs_capacity = self.current_reward_stats.get('current_capacity', 0)/2000.0
            step_contrib = self.current_reward_stats.get('step_reward_contribution', 0)
            baseline_contrib = self.current_reward_stats.get('dynamic_baseline_reward_contribution', 0)
            trend_contrib = self.current_reward_stats.get('trend_reward_contribution', 0)
            
            print(f"  ç»å¯¹å®¹é‡: {abs_capacity:+.3f} | æ­¥è¿›æ”¹è¿›: {step_contrib:+.3f}(40%) | åŠ¨æ€åŸºå‡†: {baseline_contrib:+.3f}(50%) | è¶‹åŠ¿: {trend_contrib:+.3f}(10%)")
            print(f"  æ€»æ”¹è¿›å¥–åŠ±: {self.current_reward_stats.get('total_improvement_reward', 0):+.4f} | é©¬å°”å¯å¤«æ€§è´¨: âœ…")
            
            # åŠ¨æ€åŸºå‡†å¥–åŠ±åˆ†æ
            dynamic_baseline = self.current_reward_stats.get('dynamic_baseline', 0)
            current_capacity = self.current_reward_stats.get('current_capacity', 0)
            if dynamic_baseline > 0:
                baseline_ratio = (current_capacity - dynamic_baseline) / dynamic_baseline
                if baseline_ratio > 0:
                    print(f"  ğŸ¯ è¶…è¶ŠåŸºå‡† {baseline_ratio*100:+.1f}% â†’ éçº¿æ€§å¥–åŠ±: {baseline_contrib:+.3f}")
                else:
                    print(f"  ğŸ“‰ ä½äºåŸºå‡† {baseline_ratio*100:+.1f}% â†’ çº¿æ€§æƒ©ç½š: {baseline_contrib:+.3f}")
            
            # æ˜¾ç¤ºåŠ¨æ€åŸºå‡†çš„å†å²ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if hasattr(self, 'enhanced_reward_calculator'):
                baseline_info = self.enhanced_reward_calculator.get_dynamic_baseline_info()
                recent_episodes = baseline_info.get('recent_episodes_avg', [])
                if len(recent_episodes) > 1:
                    recent_trend = "ğŸ“ˆ" if recent_episodes[-1] > recent_episodes[0] else "ğŸ“‰" if recent_episodes[-1] < recent_episodes[0] else "â¡ï¸"
                    print(f"  åŸºå‡†å†å² ({len(recent_episodes)}ä¸ª): {recent_episodes[-1]:.1f} {recent_trend} (æœ€è¿‘vsæœ€æ—©: {recent_episodes[-1] - recent_episodes[0]:+.1f})")
        
        # ç³»ç»ŸçŠ¶æ€ - æ€§èƒ½+ç¼“å­˜+é‡ç½®åˆå¹¶
        perf_info = []
        if self.performance_stats['step_times']:
            avg_step_time = np.mean(self.performance_stats['step_times'][-self.episode_step:])
            perf_info.append(f"æ­¥è¿›æ—¶é—´: {avg_step_time:.3f}s")
        
        perf_info.append(f"ä¿¡é“ç¼“å­˜: {'æ˜¯' if self.episode_channel_valid else 'å¦'}")
        
        if self.channel_cache:
            cache_stats = self.channel_cache.get_cache_stats()
            if cache_stats['total_accesses'] > 0:
                perf_info.append(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']:.1%}")
        
        perf_info.append(f"å®Œå…¨é‡ç½®: {self.full_reset_count}æ¬¡")
        
        next_reset = 100 - (self.episode_count % 100)
        if next_reset == 100:
            next_reset = 0
        perf_info.append(f"è·ä¸‹æ¬¡é‡ç½®: {next_reset}è½®")
        
        print(f"ç³»ç»ŸçŠ¶æ€: {' | '.join(perf_info)}")
        
        print(f"{'='*60}\n")
    
    def get_episode_statistics(self) -> Dict:
        """è·å–episodeç»Ÿè®¡ä¿¡æ¯"""
        return {
            'episode_count': self.episode_count,
            'rewards_history': self.episode_rewards_history.copy(),
            'capacities_history': self.episode_capacities_history.copy(),
            'avg_reward_last_10': np.mean(self.episode_rewards_history[-10:]) if len(self.episode_rewards_history) >= 10 else 0,
            'avg_capacity_last_10': np.mean(self.episode_capacities_history[-10:]) if len(self.episode_capacities_history) >= 10 else 0,
            'channel_matrix_cached': self.episode_channel_valid,
            'users_count': len(self.users),
            'antennas_count': len(self.antennas)
        }
